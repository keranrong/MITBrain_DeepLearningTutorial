{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keranrong/MITBrain_DeepLearningTutorial/blob/master/convolutional_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "y6WaAOe7P92g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks tutorial\n",
        "\n",
        "**Authors:** Eugenio Piasini and Yen-Ling Kuo for the [Brains, Minds and Machines summer course 2018](http://cbmm.mit.edu/summer-school/2018)."
      ]
    },
    {
      "metadata": {
        "id": "s8crLFYsQGTR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This tutorial will show you how\n",
        "* Build, train and test a neural network in [PyTorch](https://pytorch.org/)\n",
        "* Work with convolutions\n",
        "* Visualize filters and other properties as the network during training\n",
        "\n",
        "To do the above, we will build a convolutional neural network with the purpose of classifying handwritten digits from the MNIST database.\n"
      ]
    },
    {
      "metadata": {
        "id": "MEozv9crQVyf",
        "colab_type": "code",
        "outputId": "4b10735e-558e-4fa0-8cf2-5e3e3597fd3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# import modules we will use for the tutorial\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# install and import torch-related modules\n",
        "!pip3 install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "\n",
        "# detect if a GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on device: {}\".format(device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\r\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\r\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.2.0)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\r\n",
            "Running on device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8ZNbLMUtTaA-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up TensorBoard\n",
        "\n",
        "[Tensorboard](https://www.tensorflow.org/guide/summaries_and_tensorboard) is a utility to record and visualize the activations, weights, loss, etc of your network, during and after training. It greatly simplifies debugging and iterative development of the network architecture. It is highly recommended.\n",
        "\n",
        "To use TensorBoard in this notebook, we have to overcome two technical hurdles:\n",
        " 1. we will be using [PyTorch](https://pytorch.org/) to work with our networks, but as the name suggests, TensorBoard is designed to work with [TensorFlow](https://www.tensorflow.org/), a competing framework.\n",
        " 2. generally it is easiest to use TensorBoard when you're working on your local computer or on a computer on your local network, but in this tutorial we will run these notebooks on remote virtual machines via Colab.\n",
        "\n",
        "It is not important that you understand exactly how we are getting around these issues (this is not the point of the tutorial!), but the code is below for your reference. We will be using a tool called [`tensorboardx`](https://github.com/lanpa/tensorboardX) ([documentation](https://tensorboardx.readthedocs.io/en/latest/?badge=latest)) to overcome problem 1, and one called `ngrok` to deal with problem 2. If you're running this on your local computer, you only need to worry about problem 1 and `tensorboardx`, and can safely disregard `ngrok`.\n",
        "\n",
        "After running the following cell, a link should appear, that you can follow to see your newly created TensorBoard interface."
      ]
    },
    {
      "metadata": {
        "id": "vEBZvFOOQRh-",
        "colab_type": "code",
        "outputId": "7bdafbdb-dab4-4886-a720-8af7c903bdf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "cell_type": "code",
      "source": [
        "# download and unzip 'ngrok', the tool we will use to set up the tunnel\n",
        "ngrok_filename = 'ngrok-stable-linux-amd64.zip'\n",
        "!if [ ! -f $ngrok_filename ]; then wget https://bin.equinox.io/c/4VmDzA7iaHb/$ngrok_filename && unzip $ngrok_filename; fi\n",
        "\n",
        "# specify where we will write the logging data files to be read by TensorBoard\n",
        "LOG_DIR = './runs'\n",
        "\n",
        "# ensure the selected directory exists\n",
        "!mkdir -p $LOG_DIR\n",
        "\n",
        "# start TensorBoard\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "# open the tunnel with ngrok\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "# display a link to the TensorBoard URL\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Public TensorBoard URL: {}'.format(json.load(sys.stdin)['tunnels'][0]['public_url']))\"\n",
        "    \n",
        "# set up tensorboardx, which we will use to log stuff from pytorch\n",
        "!pip3 install tensorboardX\n",
        "from tensorboardX import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-18 15:50:49--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.0.104.144, 34.239.63.98, 34.238.48.57, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.0.104.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  7.71MB/s    in 0.7s    \n",
            "\n",
            "2018-08-18 15:50:50 (7.71 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "Public TensorBoard URL: http://c5b4271e.ngrok.io\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/d2/e08fe62f3554fbba081e80f6b23128df53b2f74ed4dcde73ec4a84dc53fb/tensorboardX-1.4-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (39.1.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "33QuvcBcT4Te",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The MNIST database\n",
        "\n",
        "[The MNIST database](https://en.wikipedia.org/wiki/MNIST_database) is a simple computer vision dataset. \n",
        "- It consists of images of handwritten digits from 0-9, and their image labels;\n",
        "- Each image is 28px * 28px;\n",
        "- The dataset is divided in two subsets, a \"training\" one containing 50000 samples and a \"testing\" one containing 10000 samples.\n",
        "<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" alt=\"MNIST sample images.\"><br>Sample MNIST images. Image by <a href=\"//commons.wikimedia.org/w/index.php?title=User:Jost_swd15&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Jost swd15 (page does not exist)\">Josef Steppan</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=64810040\">Link</a></p>\n",
        "\n",
        "How do we load the images and their labels to train and test our models? As with other important datasets, PyTorch has [a convenient interface](https://pytorch.org/docs/stable/torchvision/datasets.html#) that simplifies our life. We want to use this interface to create \"data loaders\" that will enable us to access the data. We will actually do it twice for the training set, as we want to make sure all data we use for training and testing the network is normalized. Because of this, we'll load the training data first, compute the average and the standard deviation across all pixels in the dataset, and use those numbers to define new `train` and `test` data loaders that will automatically normalize all data going forward."
      ]
    },
    {
      "metadata": {
        "id": "mx7RVSreT1es",
        "colab_type": "code",
        "outputId": "11aa727e-eca3-43a8-831a-993b07ce1121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# note that PyTorch will automatically download the data from the internet the\n",
        "# first time we ask it to load it. Hence we have to specify where it should keep\n",
        "# the data\n",
        "data_folder = \"./data\"\n",
        "\n",
        "# define a data loader that we will only use to compute mean and standard\n",
        "# deviation on the training set, with the purpose of normalizing all data\n",
        "trainset_unnormalized = torchvision.datasets.MNIST(root=data_folder, train=True,\n",
        "                                                  download=True, transform=torchvision.transforms.ToTensor())\n",
        "unnormalized_loader = torch.utils.data.DataLoader(trainset_unnormalized,\n",
        "                                                  batch_size=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ux-JRHl5wbcl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before continuing, let's have a look at our raw data to see if it actually looks like hadwritten digits."
      ]
    },
    {
      "metadata": {
        "id": "fYNkNjdEwmcT",
        "colab_type": "code",
        "outputId": "638e7964-219d-4631-cd7c-3a2c2b195e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "cell_type": "code",
      "source": [
        "def imshow(img, ax=None):\n",
        "  \"\"\"Plot a PyTorch image using matplotlib\"\"\"\n",
        "  npimg = img.numpy()\n",
        "  if ax is None:\n",
        "    fig, ax = plt.subplots()\n",
        "  npimg = np.transpose(npimg, (1,2,0)) # this is needed as torch uses a (channel, height, width) representation while matplotlib usees (width, height, channel)\n",
        "  \n",
        "  npimg = (npimg - npimg.min(axis=(0,1)))/(npimg.max(axis=(0,1))-npimg.min(axis=(0,1))) # map the values to the interval [0,1] for each channel\n",
        "  ax.imshow(npimg)\n",
        "  ax.grid(False)\n",
        "\n",
        "# load one batch of images from the training set\n",
        "dataiter = iter(unnormalized_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# it will be useful, in the next cell, to be sure of the size of the images\n",
        "# (we know MNIST is 28x28 but it's better to make sure). In pytorch, batches of\n",
        "# data are organized as follows: (batch, channels, height, width), so if we want\n",
        "# the total number of pixels we have to multiply entries 2 and 3 of the size tuple\n",
        "# (remember that python uses 0-indexing)\n",
        "n_pixels = images.size()[2]*images.size()[3]\n",
        "\n",
        "# only keep the first 16 items of the minibatch for ease of visualization\n",
        "images = images[:16]\n",
        "labels = labels[:16]\n",
        "\n",
        "# print labels\n",
        "print('True labels for the images below:', ' '.join(('{}'.format(j) for j in labels)))\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True labels for the images below: 5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAB4CAYAAAA9mHODAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa6230f5240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OcTeTnwRwYLB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# iterate over the training images, keeping a running average of the pixel value\n",
        "# and their second power. We are performing this iteration in batches of 1000\n",
        "# images at the time (controlled by the batch_size parameter in the line above).\n",
        "# Strictly speaking this is unnecessary as the whole dataset can easily fit into\n",
        "# memory, but we'll do it anyway to show how to iterate over a dataset in\n",
        "# batches using a data loader.\n",
        "n_total_images = len(trainset_unnormalized)\n",
        "train_mean = 0\n",
        "train_mean_squares = 0\n",
        "for i, data in enumerate(unnormalized_loader):\n",
        "  images, labels = data\n",
        "  train_mean += images.sum()/(n_total_images*n_pixels)\n",
        "  train_mean_squares += images.pow(2).sum()/(n_total_images*n_pixels)\n",
        "  \n",
        "train_std = (train_mean_squares-train_mean.pow(2)).sqrt()\n",
        "\n",
        "# now that we have the mean and the standard deviation, define the data loaders\n",
        "# we'll actually use such that the data will be automatically standardized at\n",
        "# load time.\n",
        "\n",
        "load_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                                 torchvision.transforms.Normalize((train_mean,), (train_std,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root=data_folder, train=True,\n",
        "                                      download=True, transform=load_transform)\n",
        "testset =  torchvision.datasets.MNIST(root=data_folder, train=False,\n",
        "                                      download=True, transform=load_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p2oOMRvPwKAR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define and instantiate the network"
      ]
    },
    {
      "metadata": {
        "id": "lKgQ5JOxmYEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # in PyTorch, we often specify all layers of the network that require hyperparameters\n",
        "    # by creating them here inside __init__. The connections between layers will\n",
        "    # be established below, inside the forward() method. Note that the order in\n",
        "    # which we create them here does not matter, as the connections between them\n",
        "    # will be specified by the forward() method below.\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, padding=2, out_channels=32, kernel_size=5) # what is the output size?\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # what is the output size?\n",
        "    self.conv2 = nn.Conv2d(in_channels=32, padding=2, out_channels=64, kernel_size=5)# what is the output size?\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # what is the output size?\n",
        "    self.fc1 = nn.Linear(in_features=64*7*7, out_features=1024) # where is the value passed as the in_features argument coming from?\n",
        "    self.fc2 = nn.Linear(in_features=1024, out_features=10)\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # this method specifies how the network processes its inputs - in other words, it describes the network's connectivity.\n",
        "    \n",
        "    # first convolution, followed by ReLU nonlinearity and pooling\n",
        "    x = self.pool1(F.relu(self.conv1(x)))\n",
        "    \n",
        "    # second convolution, followed by ReLU nonlinearity and pooling    \n",
        "    x = self.pool2(F.relu(self.conv2(x)))\n",
        "    \n",
        "    # reshape layer (concatenate all features, removing their \"topographic\" arrangement)\n",
        "    x = x.view(-1, 64*7*7)\n",
        "    \n",
        "    # first fully connected layer (with ReLU nonlinearity)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    \n",
        "    # dropout (regularization)\n",
        "    x = self.dropout(x)\n",
        "    \n",
        "    # second fully connected layer\n",
        "    x = self.fc2(x)\n",
        "    \n",
        "    # softmax (\"squashing nonlinearity\") operation. This maps all values to the \n",
        "    # [0,1] interval, so that the final output can be interpreted as the \n",
        "    # probability of belonging to each of the 10 classes. Note that here, for \n",
        "    # easier later processing, we're actually computing the log of the softmax,\n",
        "    # so the outputs can be interpreted as log-probabilities.\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a2H-zOvkvWUt",
        "colab_type": "code",
        "outputId": "23b441d6-0a02-472e-9fcd-9777c43e69ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "# instantiate network\n",
        "net = Net()\n",
        "\n",
        "# move network to GPU if available\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.5)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "c6zqF3ugNyt6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define useful functions for visualization\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "v1bIwse0N3pB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_filter_image(layer, use_color=True, scale_each=True):\n",
        "  \"\"\"Build an image of the weights of the filters in a given convolutional layer.\"\"\"\n",
        "  weights = layer.weight.data.to(\"cpu\")\n",
        "  if not use_color:\n",
        "    n_input_channels = weights.size()[1]\n",
        "    weights = weights.view([weights.size()[0], 1, weights.size()[1]*weights.size()[2], weights.size()[3]])\n",
        "  img = torchvision.utils.make_grid(weights, normalize=True, scale_each=scale_each)\n",
        "  return img\n",
        "  \n",
        "def visualize_filters(layer, use_color=True, scale_each=True):\n",
        "  \"\"\"Plot the weights of the filters in a given convolutional layer.\n",
        "  \n",
        "    \n",
        "  If use_color is true (default), the input layer is expected to have either 1 (grayscale)\n",
        "  or 3(rgb) channels. This is useful for plotting the weights of the first hidden\n",
        "  layer of the network. If you want to plot the weights of later layer, where the\n",
        "  number of input channels is arbitrary set use_color to false.\n",
        "  \n",
        "  If scale_each is true (default), the values in each filter will be scaled\n",
        "  independently before plotting; this makes the features of each individual\n",
        "  filter stand out more. If it's false, the scaling will be done globally\n",
        "  across all filters; this allows one to compare the filters.\"\"\"\n",
        "  \n",
        "  img = make_filter_image(layer, use_color=use_color, scale_each=scale_each)\n",
        "  size = 4+max(img.size())/10\n",
        "  fig, ax = plt.subplots(figsize=(size,size))\n",
        "  imshow(img, ax)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fSR7U9JMlD12",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define the loss function\n",
        "As a loss function, a standard choice for a classification problem is the cross entropy loss. The cross entropy between two discrete distributions $p[i]$ and $q[i]$ is defined as\n",
        "$$\n",
        "H(p,q) = -\\sum_i p[i]\\log(q[i])\n",
        "$$\n",
        "\n",
        "In a classification problem, the index $i$ above would refer to the different classes we're trying to assign our data to. If we have a sample whose true class is class $c$, we say that the true probability distribution over classes for that sample is $p[i]=\\delta_{i,c}$, namely $p[i]=1$ if $i=c$ and $p[i]=0$ otherwise. The distribution $q$, on the other hand, is what comes from our neural network: if the last hidden layer is $\\mathbf{h}$ and the outputs are computed by the \"squashing nonlinearity\" softmax,\n",
        "$$\n",
        "q[i] = \\frac{\\exp(h_i)}{\\sum_j\\exp{h_j}}\n",
        "$$\n",
        "\n",
        "If we plug these values into the expression for the relative entropy, we get\n",
        "$$\n",
        "H(p,q) = -\\sum_i \\delta_{i,c}\\log\\left(\\frac{\\exp(h_i)}{\\sum_l\\exp(h_l)}\\right) = -\\log\\left(\\frac{\\exp(h_c)}{\\sum_l\\exp(h_l)}\\right)\n",
        "$$\n",
        "We note that the last expression corresponds to the negative log likelihood of the data under the model defined by the network (i.e. it's just minus the log of the probability assigned by the network to the correct class). Hence, in PyTorch, to compute this function we use the [negative log likelihood loss](https://pytorch.org/docs/stable/nn.html?highlight=crossentropy#nllloss) class. Note that PyTorch also has a [CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html?highlight=crossentropy#crossentropyloss) class that combines the softmax and the negative log likelihood if you don't want to compute them in separate steps.\n",
        "\n",
        "During the optimization of our network we will also impose L2 regularization. Conceptually, this should be an added term to the loss function:\n",
        "$$\n",
        "\\mathcal{L} = \\tilde{\\mathcal{L}} + \\lambda\\frac{1}{2}\\|\\mathbf{w}\\|^2 \n",
        "$$\n",
        "where $\\tilde{\\mathcal{L}}$ is our original loss function, $\\|\\mathbf{w}\\|^2$ is the square norm of the weight vector, and $\\lambda$ a hyperparameter controlling the strength of the regularization and to be set by crossvalidation. As this is a very common form of regularization, PyTorch offers a convenient shortcut for implementing it, by simply passing $\\lambda$ as the `weight_decay` parameter to the optimizer (see the definition of the optimizer in the next cell). The reason for the name of the parameter is that, for each weight $w$, the L2 regularization term adds to the gradient the following term:\n",
        "$$\n",
        "-\\frac{\\partial}{\\partial w}\\left(\\frac{1}{2}\\lambda w^2\\right) = -\\lambda w\n",
        "$$\n",
        "which has the effect of decaying the weight linearly towards zero.\n",
        "\n",
        "### Aside: cross entropy and Kullback-Leibler divergence\n",
        "Finally, another observation on the cross entropy loss. Note that the cross entropy can also be written as\n",
        "$$\n",
        "H(p,q) = H(p) + D_{KL}(p,q) = -\\sum_i p[i]\\log(p[i]) + \\sum_i p_i \\log\\left(\\frac{p[i]}{q[i]}\\right)\n",
        "$$\n",
        "where $D_{KL}(p,q)$ is the [Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between $p$ and $q$, and is a measure of dissimilarity between two probability distributions. In general, minimizing $H(p,q)$ with respect to some parameters $\\Theta$ when only $q$ depends on $\\Theta$ (as in our case, since we are minimizing with respect to the parameters of the networks, which only affect the network's output $q$) is equivalent to minimizing $D_{KL}$, and in that sense using the cross entropy loss means driving our network to reproduce the true probability distribution. Note that in the particular case of classification, with the choice for $p$ that we made above ($p[i]=\\delta_{i,c}$), it is easy to see that $H(p)=0$, and therefore $H(p,q)=D_{KL}(p,q)$."
      ]
    },
    {
      "metadata": {
        "id": "8nz-U-mJlC5w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# negative log likelihood loss (same as cross entropy in our case)\n",
        "criterion = nn.NLLLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nppnr7nh3EvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define an optimizer\n",
        "\n",
        "For this example we will simply use stochastic gradient descent with momentum. Given a loss function $\\mathcal{L}$, the update rule for weight $w$ is\n",
        "$$\n",
        "\\Delta w := -\\eta\\frac{\\partial\\mathcal{L}}{\\partial w} + \\alpha \\Delta w\n",
        "$$\n",
        "where $\\eta$ is the learning rate and $\\alpha$ is the momentum parameter.\n",
        "\n",
        "Have a look at PyTorch's [documentation](https://pytorch.org/docs/stable/optim.html#algorithms) to see what other optimizers are available - feel free to experiment and see what happens!"
      ]
    },
    {
      "metadata": {
        "id": "uUNkBJAc5m0e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, c) # for the weight_decay parameter, see explanation in the cell above (L2 regularization)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "guLdmWZllrlr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the network"
      ]
    },
    {
      "metadata": {
        "id": "4572SNd2ll2e",
        "colab_type": "code",
        "outputId": "d3a0efe2-c9ec-4960-8ea3-5c5b1424ff5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "cell_type": "code",
      "source": [
        "# number of epochs (iterations over the whole training dataset) we want to train\n",
        "# the model for. A very small number should be sufficient (1 or 2), but if you \n",
        "# are running this on a GPU you can also try increasing it, since it's much faster\n",
        "# that way.\n",
        "n_epochs = 2\n",
        "\n",
        "# set the network in \"training mode\". This affects the behaviour of the dropout \n",
        "# layer by \"activating\" it.\n",
        "net.train() \n",
        "\n",
        "# initialize logger\n",
        "writer = SummaryWriter()\n",
        "\n",
        "plot_iteration = 0\n",
        "for epoch in range(n_epochs):\n",
        "  \n",
        "  running_loss = 0 # we will update this value with a running average of the loss, computed by hand, to print during trainig. Note that the loss can also be seen on TensorBoard, and the plot has a smoothing option.\n",
        "  for i, data in enumerate(trainloader):\n",
        "    # get the next minibatch of data\n",
        "    inputs, labels = data\n",
        "    \n",
        "    # move data and labels to GPU if available\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # zero the gradients (this is needed because PyTorch accumulates gradients \n",
        "    # in all parameters every time we call loss.backward())\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward propagation of inputs: compute the activation of all units within the network\n",
        "    outputs = net(inputs)\n",
        "    \n",
        "    # compute the loss\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    # backpropagation: compute the numerical gradient of the loss with respect to\n",
        "    # all parameters, evaluated for the current values of the activations and the loss.\n",
        "    # As mentioned above, these values are stored locally within each parameter.\n",
        "    loss.backward()\n",
        "    \n",
        "    # take a step with the optimizer we have defined above. The optimizer will \n",
        "    # go through all the parameters it know about (which we have specified when\n",
        "    # we created it), and update them according to the gradients it will find there,\n",
        "    # which we have computed when we performed backpropagation.\n",
        "    optimizer.step()\n",
        "    \n",
        "    # print some statistics\n",
        "    running_loss += loss.item() # the .item() method casts a pytorch tensor of size 1 to a simple python scalar\n",
        "    if i % 10 == 0:\n",
        "      # every ten minibatches, send a picture of the 1st layer filters and the \n",
        "      # value of the loss to TensorBoard, which will automatically figure out how to plot them.\n",
        "      writer.add_image('Layer 1 filters', make_filter_image(net.conv1), plot_iteration)\n",
        "      writer.add_scalar('Loss', loss.item(), plot_iteration)\n",
        "      plot_iteration += 1\n",
        "    if i % 100 == 99:\n",
        "      # every 100 minibatches, print some information in the cell output.\n",
        "      print(\"[epoch {}, iter {}] loss: {:.3f}\".format(epoch+1, i+1, running_loss/100))\n",
        "      running_loss = 0\n",
        "\n",
        "# close the logger\n",
        "writer.close()\n",
        "\n",
        "print(\"Finished training\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch 1, iter 100] loss: 0.559\n",
            "[epoch 1, iter 200] loss: 0.194\n",
            "[epoch 1, iter 300] loss: 0.139\n",
            "[epoch 1, iter 400] loss: 0.139\n",
            "[epoch 1, iter 500] loss: 0.128\n",
            "[epoch 1, iter 600] loss: 0.149\n",
            "[epoch 2, iter 100] loss: 0.119\n",
            "[epoch 2, iter 200] loss: 0.103\n",
            "[epoch 2, iter 300] loss: 0.137\n",
            "[epoch 2, iter 400] loss: 0.120\n",
            "[epoch 2, iter 500] loss: 0.122\n",
            "[epoch 2, iter 600] loss: 0.125\n",
            "Finished training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X343ZkMMrWTE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test on held out data"
      ]
    },
    {
      "metadata": {
        "id": "tuyeu52rqJj3",
        "colab_type": "code",
        "outputId": "2e421cf1-ba9f-44e2-fa86-565c0ecd6afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "cell_type": "code",
      "source": [
        "net.eval() # set the network in evaluation mode (as opposed to training mode; see comment above when we called net.train())\n",
        "\n",
        "# load a set of example images from the testing set\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "num_examples = images.size()[0]\n",
        "\n",
        "# plot the examples\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# move the examples and the labels to the GPU if available (if the network is on the GPU, we have to move any data there before processing it!)\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# compute predictions and bring them back to the CPU\n",
        "outputs = net(images)\n",
        "_, predictions = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "#print(' '.join(('{}'.format(j) for j in labels)))\n",
        "print(\"Ground truth: \", \" \".join(\"{}\".format(labels[j]) for j in range(num_examples)))\n",
        "print(\"Predicted:    \", \" \".join(\"{}\".format(predictions[j]) for j in range(num_examples)))\n",
        "print(\"Accuracy: {}%\".format(100*(labels==predictions).sum()/num_examples))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ground truth:  7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9\n",
            "Predicted:     7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 5 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 8 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9\n",
            "Accuracy: 98%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKwAAAD8CAYAAADqv08vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOlCo4DBYBwoVHAbrQKHC/wNaQwiXxwcu2gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa61e2cb978>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3rIiHLxpzOXD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize filters\n",
        "The filters of the trained network can be visualized by using the same function we used to generate the images to send to TensorBoard during training (but you are encouraged to use TensorBoard and look at how the filters evolved from their initial state!).\n",
        "\n",
        "Looking at the plot below, do you see any interesting pattern?"
      ]
    },
    {
      "metadata": {
        "id": "MkdXnSIlzW8K",
        "colab_type": "code",
        "outputId": "c6aec212-960c-4509-cf15-79472862275a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "cell_type": "code",
      "source": [
        "visualize_filters(net.conv1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAE6CAYAAAAV/FYPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAAASNr/B9wO7EF6CiT5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa58c14fc88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lA-au5I9DHo-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercise\n",
        "\n",
        "Now try to implement a convolutional network that performs image classification on [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). CIFAR10 is an established computer-vision dataset used for object recognition. It is a subset of the [80 million tiny images dataset](http://people.csail.mit.edu/torralba/tinyimages/) and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class. The object classes are the following:\n",
        "\n",
        "\n",
        "0. Airplane\n",
        "1. Automobile\n",
        "2. Bird\n",
        "3. Cat\n",
        "4. Deer\n",
        "5. Dog\n",
        "6. Frog\n",
        "7. Horse\n",
        "8. Ship\n",
        "9. Truck\n",
        "\n",
        "<p><img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/3649/media/cifar-10.png\" alt=\"CIFAR sample images.\" style=\"width: 500px;\"><br>Sample CIFAR images.</p>\n",
        "\n",
        "\n",
        "Like MNIST, CIFAR is accessible [directly from within PyTorch](https://pytorch.org/docs/stable/torchvision/datasets.html#cifar); the data loader interface should look very similar. You can start by implementing an architecture like the one we used for MNIST, and by training it in a similar way. **Note that the input is RGB color, and has a different size than MNIST (CIFAR is 3x32x32 while MNIST is 1x28x28), so you'll probably have to start by adjusting your architecture to cope with that**. After getting it to run, you can experiment with altering it to see what happens if you add, remove or change the size of filters, add or remove layers, etc."
      ]
    },
    {
      "metadata": {
        "id": "pzJOxVmBwFha",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Let's move to the next tutorial: [transfer learning](https://colab.research.google.com/drive/15exgMLrj7azSMQeKXBYwuHZAdJdCQloh).\n"
      ]
    },
    {
      "metadata": {
        "id": "DzYP6fAcwZMA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# uncomment and run this if you want to delete all TensorBoard logs\n",
        "#!rm -r $LOG_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NCWFNrY78BkY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}